{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**THEORY**"
      ],
      "metadata": {
        "id": "qxhF-2Aib8NF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is the difference between multiple model training and single model training?\n",
        "Multiple model training involves training various models and aggregating their predictions, whereas single model training relies on just one model.Ensemble techniques leverage multiple models to enhance accuracy, reduce variance, and improve robustness compared to single model approaches.\n"
      ],
      "metadata": {
        "id": "jNjB_2SLb-Px"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is the role of bootstrap sampling in Bagging?\n",
        " Bootstrap sampling generates multiple training subsets by randomly selecting data points with replacement. This allows for training different models on diverse datasets, improving robustness and reducing variance.\n"
      ],
      "metadata": {
        "id": "KMN8raWKcAvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How do you evaluate a Bagging Classifier’s performance?\n",
        " Performance of a Bagging Classifier can be evaluated using accuracy, precision, recall, F1-score, and OOB Score Accuracy measures overall correct predictions, while precision and recall help assess performance in imbalanced datasets OOB Score is a useful metric that leverages out-of-bag samples for evaluation, reducing the need for a separate validation set.\n"
      ],
      "metadata": {
        "id": "c0ttiKGCcDXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What is OOB (Out-of-Bag) Score?\n",
        "OOB Score is an estimate of model performance calculated using the samples that were not selected in the bootstrap process.Since Bagging trains multiple models on different random subsets, some instances are left out of training and can be used for validation without needing a separate test set.\n"
      ],
      "metadata": {
        "id": "1OM38u3gcFgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Explain the key idea behind ensemble techniques.\n",
        "The key idea is to use multiple models and aggregate their predictions. By combining different models, ensemble methods reduce overfitting, improve accuracy, and make predictions more robust.These methods often rely on diverse models that complement each other, leading to better overall performance compared to individual models.\n"
      ],
      "metadata": {
        "id": "9NSaKaa8cJvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. What are the main types of ensemble techniques?\n",
        "The main types include Bagging, Boosting, and Stacking.\n"
      ],
      "metadata": {
        "id": "LYUK3TmHcN0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. What is ensemble learning in machine learning?\n",
        "Ensemble learning is a technique that combines multiple models to improve predictive performance and robustness.\n"
      ],
      "metadata": {
        "id": "wD3aZyW4cPxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. How does a Bagging Regressor work?\n",
        "A Bagging Regressor averages predictions from multiple regression models trained on bootstrapped data samples.\n",
        " This technique reduces variance and improves stability in regression problems by preventing a single model from overly fitting to the training data.\n"
      ],
      "metadata": {
        "id": "x8APEFwscSVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. What is the main challenge of ensemble methods?\n",
        " The main challenge is computational complexity, as multiple models need to be trained and combined.\n",
        "This increases training time and memory usage. Additionally, ensemble models are harder to interpret compared to simpler models like decision trees or linear regression.\n"
      ],
      "metadata": {
        "id": "Y88n2-V2cULV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. Why is Random Forest better than a single Decision Tree?\n",
        "Random Forest reduces overfitting by averaging multiple trees, leading to better generalization. A single decision tree may perform well on training data but overfit to noise, whereas Random Forest uses multiple trees trained on different subsets to provide a more stable prediction.\n"
      ],
      "metadata": {
        "id": "Eh5ypcGYcWCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. What is the difference between Bagging and Boosting?\n",
        "Bagging trains models independently and averages their outputs, whereas Boosting trains models sequentially, focusing on misclassified examples.\n",
        " Boosting improves weak learners by assigning higher weights to misclassified instances, making the model more accurate but also prone to overfitting.\n"
      ],
      "metadata": {
        "id": "uzZAwMjjcXuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. Explain the working principle of a Bagging Classifier.\n",
        "A Bagging Classifier creates multiple instances of the same model using bootstrapped data samples.Each model is trained on a different subset of data, and their predictions are aggregated (e.g., by majority voting for classification).\n",
        " This helps to improve accuracy, reduce overfitting, and make the model more robust to noise in the dataset.\n"
      ],
      "metadata": {
        "id": "WUctNFnocaxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13. How does Bagging help in reducing overfitting?\n",
        "Bagging reduces overfitting by training multiple models on different subsets of data and averaging their predictions.\n",
        " By training multiple weak learners on random subsets of data, Bagging increases model stability and reduces variance, leading to better generalization on unseen data.\n"
      ],
      "metadata": {
        "id": "LXBWPQWecc3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14. What is a Random Forest Classifier?\n",
        "A Random Forest Classifier is an ensemble of decision trees trained using Bagging and feature randomness for better accuracy.\n"
      ],
      "metadata": {
        "id": "DypmKnF7cgcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Q15. How can you measure the importance of features in a Random Forest model?\n",
        " Feature importance can be measured using techniques like Gini Importance or Permutation Importance.\n",
        "These methods assess the impact of each feature on the model’s predictive power, helping in feature selection and model interpretability.\n"
      ],
      "metadata": {
        "id": "Izqu8BWQchHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q16. Explain the concept of feature randomness in Random Forest.\n",
        " Random Forest selects a random subset of features at each split in a decision tree.This ensures that trees are diverse and not overly dependent on certain features, reducing overfitting and improving model generalization.\n"
      ],
      "metadata": {
        "id": "F5vaaVBhcjC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q17. When should we avoid using ensemble methods?\n",
        "Ensemble methods should be avoided when interpretability is crucial, as they create complex models that are hard to explain.\n",
        "Additionally, if the dataset is small or computational resources are limited, simpler models may be more effective and efficient.\n"
      ],
      "metadata": {
        "id": "VKwlNDW4clH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q18. What is the main advantage of ensemble techniques?\n",
        "The main advantage is improved accuracy and robustness by reducing variance and bias.\n"
      ],
      "metadata": {
        "id": "GyTN2cVNcoEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q19. Can we use Bagging for regression problems?\n",
        "Yes, Bagging can be used for regression using a Bagging Regressor, which averages predictions from multiple models to improve stability and reduce variance.\n"
      ],
      "metadata": {
        "id": "_XL90l5mcqTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q20. What are some real-world applications of ensemble techniques?\n",
        " Ensemble methods are widely used in fraud detection, medical diagnosis, recommendation systems, and image classification.These techniques improve predictive accuracy, making them useful in industries that require high reliability and precision.\n"
      ],
      "metadata": {
        "id": "VTzVX4UlcsNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRACTICAL**"
      ],
      "metadata": {
        "id": "NTtEggwScyKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy."
      ],
      "metadata": {
        "id": "4MEEcnqbcz1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Bagging Classifier with Decision Trees\n",
        "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Bagging Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au03DQkYc2KH",
        "outputId": "147b99f2-b2cb-40cb-f249-9bf4f3bee580"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)."
      ],
      "metadata": {
        "id": "syMKMjN0c-XM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_regression(n_samples=500, n_features=4, noise=0.1, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Bagging Regressor\n",
        "model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=15, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Bagging Regressor MSE:\", mean_squared_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF_u_9TRdASt",
        "outputId": "f4d0ca07-00f8-4efc-90a0-713aed2d9f73"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor MSE: 190.28937726305065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores."
      ],
      "metadata": {
        "id": "ipxpR9HndEsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=20, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importance\n",
        "print(\"Feature Importances:\", model.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nLRa63CdGki",
        "outputId": "f1a790aa-3426-422b-bb63-8be570594f92"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances: [0.09389798 0.01877596 0.03209534 0.0353801  0.0085131  0.02477505\n",
            " 0.06971444 0.12637211 0.00547855 0.00354851 0.03643317 0.0072133\n",
            " 0.00774274 0.0660334  0.00356888 0.0034282  0.01114746 0.00448966\n",
            " 0.00460848 0.00688001 0.05943534 0.01430702 0.07393636 0.07405907\n",
            " 0.00344462 0.03205183 0.01789973 0.14169879 0.00807492 0.00499585]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q24. Train a Random Forest Regressor and compare its performance with a single Decision Tree."
      ],
      "metadata": {
        "id": "btz72FBddJ4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_regression(n_samples=300, n_features=6, noise=0.2, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Regressor\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=15, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Compare R-squared scores\n",
        "print(\"Decision Tree R2 Score:\", r2_score(y_test, dt_pred))\n",
        "print(\"Random Forest R2 Score:\", r2_score(y_test, rf_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6pB_dpTdLzC",
        "outputId": "78ce389a-2a13-448e-9775-81775386eee1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree R2 Score: 0.6870379024847741\n",
            "Random Forest R2 Score: 0.8664631475261791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier."
      ],
      "metadata": {
        "id": "Mh4VtDZrdOy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=400, n_features=5, random_state=42)\n",
        "\n",
        "# Train Random Forest with OOB Score enabled\n",
        "model = RandomForestClassifier(n_estimators=15, oob_score=True, random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print OOB Score\n",
        "print(\"OOB Score:\", model.oob_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAyr-XHDdQpP",
        "outputId": "69fe80d8-5092-44f1-b9f5-0768b58a9aab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 0.9225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q26. Train a Bagging Classifier using SVM as a base estimator and print accuracy."
      ],
      "metadata": {
        "id": "n7ZgSDKSdTa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=4, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Bagging Classifier with SVM\n",
        "model = BaggingClassifier(estimator=SVC(), n_estimators=10, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Bagging Classifier (SVM) Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTiWJJpYdVEt",
        "outputId": "d339dae7-38d2-4190-8232-62709e7f8f84"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier (SVM) Accuracy: 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q27. Train a Random Forest Classifier with different numbers of trees and compare accuracy."
      ],
      "metadata": {
        "id": "fH2TTccKdX5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest with different numbers of trees\n",
        "for n_trees in [5, 10, 50, 100]:\n",
        "    model = RandomForestClassifier(n_estimators=n_trees, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"Accuracy with {n_trees} trees:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FLItGEadZ9N",
        "outputId": "01090e07-57ea-48c3-c9ff-0b413f02d7d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with 5 trees: 0.95\n",
            "Accuracy with 10 trees: 0.94\n",
            "Accuracy with 50 trees: 0.96\n",
            "Accuracy with 100 trees: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score."
      ],
      "metadata": {
        "id": "yqi1onimdltQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=600, n_features=4, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Bagging Classifier with Logistic Regression\n",
        "model = BaggingClassifier(estimator=LogisticRegression(), n_estimators=10, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate using AUC\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "print(\"AUC Score:\", roc_auc_score(y_test, y_prob))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5tPxUXmdmeE",
        "outputId": "66d0bb14-c30f-474e-99f5-0b233eb650fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score: 0.961352657004831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q29. Train a Random Forest Regressor and analyze feature importance scores"
      ],
      "metadata": {
        "id": "P6zHkYLIdq5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_regression(n_samples=400, n_features=6, noise=0.3, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=20, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importance\n",
        "print(\"Feature Importances:\", model.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0nK09KCdtPa",
        "outputId": "3b209e51-dcad-48f6-e565-5e5ba6f0b50e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances: [0.2462535  0.01016018 0.05553606 0.67049721 0.00889836 0.00865468]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q30. Train an ensemble model using both Bagging and Random Forest and compare accuracy."
      ],
      "metadata": {
        "id": "IEVhg3iXdwMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Bagging Classifier with Decision Trees\n",
        "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "bagging_model.fit(X_train, y_train)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate models\n",
        "bagging_acc = accuracy_score(y_test, bagging_model.predict(X_test))\n",
        "rf_acc = accuracy_score(y_test, rf_model.predict(X_test))\n",
        "\n",
        "print(\"Bagging Classifier Accuracy:\", bagging_acc)\n",
        "print(\"Random Forest Classifier Accuracy:\", rf_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6upfo_idySN",
        "outputId": "42fcff3c-1514-4a91-aefc-04846c6e0475"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.95\n",
            "Random Forest Classifier Accuracy: 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV."
      ],
      "metadata": {
        "id": "BB7DoN4hd1kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=6, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100],\n",
        "    'max_depth': [None, 5, 10]\n",
        "}\n",
        "\n",
        "# Train model with GridSearchCV\n",
        "model = GridSearchCV(RandomForestClassifier(), param_grid, cv=3)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best Parameters:\", model.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7fommqfd3ie",
        "outputId": "88b0cdf6-5d90-4bce-b921-a7e03d2e63f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 5, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q32. Train a Bagging Regressor with different numbers of base estimators and compare performance."
      ],
      "metadata": {
        "id": "5JjbSym4d7Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=6, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100],\n",
        "    'max_depth': [None, 5, 10]\n",
        "}\n",
        "\n",
        "# Train model with GridSearchCV\n",
        "model = GridSearchCV(RandomForestClassifier(), param_grid, cv=3)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best Parameters:\", model.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs2YEOCHd9nH",
        "outputId": "a75001e1-7405-4e42-bee5-9207cafa5b10"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 10, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q33. Train a Random Forest Classifier and analyze misclassified samples."
      ],
      "metadata": {
        "id": "xz7LmDgQeBc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=20, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Identify misclassified samples\n",
        "misclassified = np.where(y_test != model.predict(X_test))\n",
        "print(\"Misclassified Sample Indices:\", misclassified[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHXlOdCdeDOZ",
        "outputId": "c41d19a9-cf16-426f-9bba-123c9fb1cd34"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Misclassified Sample Indices: [ 2 11 49 72 90]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier."
      ],
      "metadata": {
        "id": "XiuGjq5qeFf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=400, n_features=6, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Single Decision Tree\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_acc = accuracy_score(y_test, dt_model.predict(X_test))\n",
        "\n",
        "# Train Bagging Classifier\n",
        "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "bagging_model.fit(X_train, y_train)\n",
        "bagging_acc = accuracy_score(y_test, bagging_model.predict(X_test))\n",
        "\n",
        "print(\"Decision Tree Accuracy:\", dt_acc)\n",
        "print(\"Bagging Classifier Accuracy:\", bagging_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgxGAnZceHYf",
        "outputId": "a29eef8b-b8b1-468d-b36c-8619aaa6f054"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.9375\n",
            "Bagging Classifier Accuracy: 0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q35. Train a Random Forest Classifier and visualize the confusion matrix."
      ],
      "metadata": {
        "id": "tltHv8GdeKGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=20, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Compute confusion matrix\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix - Random Forest\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "gLHS2JfFeL99",
        "outputId": "0afce616-9de9-4243-9475-3b898cbbdf12"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy."
      ],
      "metadata": {
        "id": "rRH9vtDFeOzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    ('dt', DecisionTreeClassifier()),\n",
        "    ('svm', SVC(probability=True))\n",
        "]\n",
        "\n",
        "# Define stacking model\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = stacking_model.predict(X_test)\n",
        "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FatGDw5feRKx",
        "outputId": "f50745ce-7621-4d41-8298-49cab24b4bb7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q37. Train a Random Forest Classifier and print the top 5 most important features."
      ],
      "metadata": {
        "id": "rPacg4mVeTjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=30, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print top 5 important features\n",
        "feature_importance = sorted(zip(feature_names, model.feature_importances_), key=lambda x: x[1], reverse=True)\n",
        "print(\"Top 5 Important Features:\", feature_importance[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvG8uwI-eVVS",
        "outputId": "b5f682bc-386f-4aad-97d5-22a19742e33f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Important Features: [('flavanoids', np.float64(0.23879579217160415)), ('color_intensity', np.float64(0.14498623162385882)), ('od280/od315_of_diluted_wines', np.float64(0.11900812539978446)), ('alcohol', np.float64(0.09290190568038877)), ('hue', np.float64(0.09092352236249875))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score."
      ],
      "metadata": {
        "id": "aXBEKJDDeYBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=4, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Bagging Classifier\n",
        "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1-Score:\", f1_score(y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2j83umGeZ8t",
        "outputId": "1ab0be53-7174-45ca-cae3-62a75eaa99f1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9291449217181855\n",
            "Recall: 0.9303542673107891\n",
            "F1-Score: 0.9296553110240177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy."
      ],
      "metadata": {
        "id": "L2G0m580ecTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=400, n_features=6, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier with different max_depth values\n",
        "for depth in [None, 5, 10, 20]:\n",
        "    model = RandomForestClassifier(n_estimators=20, max_depth=depth, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"Accuracy with max_depth={depth}:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43729Paoedyz",
        "outputId": "bb5ff196-9b10-4a7f-bf40-2007f2f5a3e5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with max_depth=None: 0.9625\n",
            "Accuracy with max_depth=5: 0.9625\n",
            "Accuracy with max_depth=10: 0.9625\n",
            "Accuracy with max_depth=20: 0.9625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance."
      ],
      "metadata": {
        "id": "jlkExTtregSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_regression(n_samples=400, n_features=5, noise=0.4, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and compare two Bagging Regressors\n",
        "models = {\n",
        "    \"DecisionTree\": BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, random_state=42),\n",
        "    \"KNeighbors\": BaggingRegressor(estimator=KNeighborsRegressor(), n_estimators=10, random_state=42)\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"MAE for {name}:\", mean_absolute_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95tosgNVeiI1",
        "outputId": "d1636651-f00d-4ba9-f08b-cb9488f9aba4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE for DecisionTree: 20.313150999663247\n",
            "MAE for KNeighbors: 23.55133904480849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score."
      ],
      "metadata": {
        "id": "LJSaOuLyelbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=6, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=20, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC-AUC Score\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYXd5zg7em82",
        "outputId": "8acd1f8f-830f-4cce-ffa3-e7961bdadc52"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9849033816425121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q42. Train a Bagging Classifier and evaluate its performance using cross-validation."
      ],
      "metadata": {
        "id": "C6nJ5sDXepoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=6, random_state=42)\n",
        "\n",
        "# Train Bagging Classifier\n",
        "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "\n",
        "# Compute cross-validation scores\n",
        "scores = cross_val_score(model, X, y, cv=5)\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Average Accuracy:\", scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tHh_IHGerkj",
        "outputId": "d8dfbafc-2915-49f1-d1f9-2f950348e317"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.9  0.92 0.95 0.93 0.97]\n",
            "Average Accuracy: 0.9339999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q43. Train a Random Forest Classifier and plot the Precision-Recall curve."
      ],
      "metadata": {
        "id": "CBCcEeWfeuGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=6, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=20, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "# Plot Precision-Recall curve\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve - Random Forest\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ciIXlh6pewOz",
        "outputId": "8aa1ee85-ef2c-46c5-9e40-edaf0d9b7a01"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy."
      ],
      "metadata": {
        "id": "aL9SbB9leywt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=6, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=10, random_state=42))\n",
        "]\n",
        "\n",
        "# Define stacking model\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = stacking_model.predict(X_test)\n",
        "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z45PGLO2e0zc",
        "outputId": "8101cfcc-e399-4061-e6a4-399a6291f0f3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance."
      ],
      "metadata": {
        "id": "Z-2-3b5Pe3sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_regression(n_samples=500, n_features=5, noise=0.3, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and compare different bootstrap sample sizes\n",
        "for max_samples in [0.5, 0.7, 1.0]:\n",
        "    model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, max_samples=max_samples, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"MSE with max_samples={max_samples}:\", mean_squared_error(y_test, y_pred))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2pweXv7e5fN",
        "outputId": "0362d574-99d8-4170-aea1-2766399a641e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE with max_samples=0.5: 1375.6392984171969\n",
            "MSE with max_samples=0.7: 1082.6526190159868\n",
            "MSE with max_samples=1.0: 1117.5481243394092\n"
          ]
        }
      ]
    }
  ]
}